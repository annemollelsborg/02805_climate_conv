{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b998eb",
   "metadata": {},
   "source": [
    "# Initial analysis of the Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dda048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78640de1",
   "metadata": {},
   "source": [
    "* Nodes = tweets\n",
    "* Edges = similarity between tweets based on meaning (embedding cosine similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d08331",
   "metadata": {},
   "source": [
    "### Load the dataset and generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/ame/02805_climate_conv/data/twitter_sentiment_data.csv\",\n",
    "                 encoding=\"latin1\",\n",
    "                 on_bad_lines=\"skip\")\n",
    "\n",
    "df[\"message\"] = df[\"message\"].astype(str)\n",
    "\n",
    "df = df[df[\"message\"].str.strip().replace(\"nan\", np.nan).notna()]\n",
    "\n",
    "def clean_text(msg):\n",
    "    msg = msg.lower()\n",
    "    msg = re.sub(r\"http\\S+\", \"\", msg)       # remove URLs\n",
    "    msg = re.sub(r\"rt\\s*@\\w+:\", \"\", msg)    # remove RT prefix\n",
    "    msg = re.sub(r\"@\\w+\", \"\", msg)          # remove mentions\n",
    "    msg = re.sub(r\"#\", \"\", msg)             # remove hashtags\n",
    "    msg = re.sub(r\"[^a-z0-9\\s]\", \" \", msg)  # keep letters/numbers\n",
    "    msg = re.sub(r\"\\s+\", \" \", msg).strip()\n",
    "    return msg\n",
    "\n",
    "df[\"clean_text\"] = df[\"message\"].apply(clean_text)\n",
    "\n",
    "df = df[df[\"clean_text\"].str.len() > 0]\n",
    "\n",
    "def is_valid_unicode(x):\n",
    "    try:\n",
    "        x.encode(\"utf-8\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df = df[df[\"clean_text\"].apply(is_valid_unicode)]\n",
    "\n",
    "df = df[df[\"clean_text\"].str.len() <= 8000]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"Final cleaned dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6457c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build nearest-neighbor search over embeddings\n",
    "\n",
    "EMBEDDINGS_PATH = \"/Users/ame/02805_climate_conv/data/tweet_embeddings.npy\"\n",
    "\n",
    "embeddings = np.load(EMBEDDINGS_PATH)\n",
    "\n",
    "print(\"Building nearest-neighbor index...\")\n",
    "\n",
    "k = 50  # number of neighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=k, metric=\"cosine\")\n",
    "nn.fit(embeddings)\n",
    "\n",
    "distances, indices = nn.kneighbors(embeddings)\n",
    "\n",
    "# Cosine similarity = 1 - cosine distance\n",
    "similarities = 1 - distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.60\n",
    "G = nx.Graph()\n",
    "\n",
    "# Make sure tweetid matches node IDs (usually strings)\n",
    "df[\"tweetid\"] = df[\"tweetid\"].astype(str)\n",
    "\n",
    "# ---- 1) ADD NODES FIRST ----\n",
    "for _, row in df.iterrows():\n",
    "    tid = row[\"tweetid\"]\n",
    "    G.add_node(\n",
    "        tid,\n",
    "        tweetid=tid,\n",
    "        sentiment=row[\"sentiment\"],   # numeric\n",
    "        message=row[\"message\"],\n",
    "        clean_text=row[\"clean_text\"],\n",
    "    )\n",
    "\n",
    "# ---- 2) MAP NUMERIC SENTIMENT → LABEL ----\n",
    "sentiment_map = {\n",
    "    2: \"news\",\n",
    "    1: \"pro\",\n",
    "    0: \"neutral\",\n",
    "    -1: \"anti\",\n",
    "}\n",
    "\n",
    "df[\"sentiment_label\"] = df[\"sentiment\"].map(sentiment_map)\n",
    "\n",
    "# Build dict: tweetid → label\n",
    "label_attr = df.set_index(\"tweetid\")[\"sentiment_label\"].to_dict()\n",
    "\n",
    "# ---- 3) NOW ADD LABELS TO EXISTING NODES ----\n",
    "nx.set_node_attributes(G, label_attr, \"sentiment_label\")\n",
    "\n",
    "# ---- 4) ADD EDGES ----\n",
    "edges_added = 0\n",
    "print(\"Building network with similarity threshold =\", THRESHOLD)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for j_idx, sim in zip(indices[i], similarities[i]):\n",
    "        if sim >= THRESHOLD and i != j_idx:\n",
    "            tid1 = df.loc[i, \"tweetid\"]\n",
    "            tid2 = df.loc[j_idx, \"tweetid\"]\n",
    "            G.add_edge(tid1, tid2, weight=float(sim))\n",
    "            edges_added += 1\n",
    "\n",
    "\n",
    "print(\"Network created.\")\n",
    "print(\"Nodes:\", G.number_of_nodes())\n",
    "print(\"Edges:\", G.number_of_edges())\n",
    "\n",
    "nx.write_gexf(G, \"/Users/ame/02805_climate_conv/networks/climate_tweet_network.gexf\")\n",
    "print(\"Graph saved to networks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30ceb9",
   "metadata": {},
   "source": [
    "### Desciption of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe130d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network from file to G\n",
    "G = nx.read_gexf(\"/Users/ame/02805_climate_conv/networks/climate_tweet_network.gexf\")\n",
    "print(\"Graph loaded from file\")\n",
    "print(\"Nodes:\", G.number_of_nodes())\n",
    "print(\"Edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddbf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average degree\n",
    "avg_degree = sum(dict(G.degree()).values()) / G.number_of_nodes()\n",
    "print(\"Average degree:\", avg_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae957635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max and min degree\n",
    "degrees = dict(G.degree()).values()\n",
    "print(\"Max degree:\", max(degrees))\n",
    "print(\"Min degree:\", min(degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae879c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of degree distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(degrees, bins=30)\n",
    "plt.title(\"Degree Distribution\")\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of nodes with 0 edges\n",
    "num_isolated = sum(1 for node in G.nodes() if G.degree(node) == 0)\n",
    "print(\"Number of nodes with 0 edges:\", num_isolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fc040",
   "metadata": {},
   "source": [
    "## Backboning and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gcc_nodes = max(nx.connected_components(G), key=len)\n",
    "Gcc = G.subgraph(Gcc_nodes).copy()\n",
    "\n",
    "# Approximate edge betweenness\n",
    "# Choose sample size k (try 100 first)\n",
    "k = 50\n",
    "\n",
    "ebc = nx.edge_betweenness_centrality(Gcc, k=k, seed=42)\n",
    "\n",
    "# Normalize betweenness to [1, 100]\n",
    "vals = np.array(list(ebc.values()))\n",
    "min_b, max_b = vals.min(), vals.max()\n",
    "\n",
    "for u, v in Gcc.edges():\n",
    "    w = ebc.get((u, v), 0.0)\n",
    "    norm_w = 1 + 99 * (w - min_b) / (max_b - min_b) if max_b > min_b else 1\n",
    "    Gcc[u][v][\"weight\"] = norm_w\n",
    "\n",
    "W1 = Gcc.copy()\n",
    "\n",
    "# Convert to DataFrame as before\n",
    "W1_edges = [\n",
    "    {\"src\": u, \"trg\": v, \"nij\": data[\"weight\"]}\n",
    "    for u, v, data in W1.edges(data=True)\n",
    "]\n",
    "\n",
    "table_W1 = pd.DataFrame(W1_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc794cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import backboning\n",
    "importlib.reload(backboning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W1 = backboning.disparity_filter(table_W1, undirected=True)\n",
    "backbone_W1 = backboning.thresholding(df_W1, threshold=0.8)\n",
    "G_backbone_W1 = nx.from_pandas_edgelist(\n",
    "    backbone_W1, source=\"src\", target=\"trg\", edge_attr=\"score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e365da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors\n",
    "sentiment_colors = {\n",
    "    \"anti\":      \"indianred\",  \n",
    "    \"pro\":       \"forestgreen\",  \n",
    "    \"neutral\":   \"silver\", \n",
    "    \"news\":      \"cornflowerblue\", \n",
    "}\n",
    "\n",
    "# Make sure backbone nodes inherit sentiment from original G\n",
    "for n in G_backbone_W1.nodes():\n",
    "    if n in G.nodes:\n",
    "        G_backbone_W1.nodes[n][\"sentiment_label\"] = G.nodes[n].get(\"sentiment_label\")\n",
    "\n",
    "# Layout ONLY for the backbone\n",
    "pos_W1 = nx.forceatlas2_layout(\n",
    "    G_backbone_W1,\n",
    "    max_iter=500,\n",
    "    gravity=0.8,\n",
    "    scaling_ratio=2.0,\n",
    "    seed=123,\n",
    "    distributed_action=False,\n",
    "    strong_gravity=True,\n",
    ")\n",
    "\n",
    "# Plot with sentiment-based coloring\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# node sizes (degree-based)\n",
    "node_sizes = [2 + G_backbone_W1.degree(n) * 5 for n in G_backbone_W1.nodes()]\n",
    "\n",
    "nx.draw_networkx_edges(G_backbone_W1, pos_W1, ax=ax, alpha=0.5)\n",
    "\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G_backbone_W1,\n",
    "    pos_W1,\n",
    "    ax=ax,\n",
    "    node_size=node_sizes,\n",
    "    alpha=1,\n",
    "    node_color=[\n",
    "        sentiment_colors.get(\n",
    "            G_backbone_W1.nodes[n].get(\"sentiment_label\"),\n",
    "            \"#7f7f7f\"  # default grey if missing\n",
    "        )\n",
    "        for n in G_backbone_W1.nodes()\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Legend\n",
    "for sentiment, color in sentiment_colors.items():\n",
    "    ax.scatter([], [], c=color, label=sentiment)\n",
    "\n",
    "ax.legend(\n",
    "    title=\"Sentiment\",\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1, 1),\n",
    ")\n",
    "\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Backbone W1 (Disparity Filter + Edge Betweenness Weighting)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66964ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [\"anti\", \"pro\", \"neutral\", \"news\"]\n",
    "\n",
    "# 1. Compute a GLOBAL layout on the full backbone\n",
    "pos_global = nx.forceatlas2_layout(\n",
    "    G_backbone_W1,\n",
    "    max_iter=800,\n",
    "    gravity=0.8,\n",
    "    scaling_ratio=2.0,\n",
    "    seed=42,\n",
    "    distributed_action=False,\n",
    "    strong_gravity=True\n",
    ")\n",
    "\n",
    "# 2. Build sentiment-specific backbone subnetworks\n",
    "subgraphs_backbone = {\n",
    "    s: G_backbone_W1.subgraph([\n",
    "        n for n in G_backbone_W1.nodes()\n",
    "        if G.nodes[n].get(\"sentiment_label\") == s\n",
    "    ]).copy()\n",
    "    for s in sentiments\n",
    "}\n",
    "\n",
    "# 3. Plot using SAME POSITIONS\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 6))\n",
    "\n",
    "for ax, sentiment in zip(axes, sentiments):\n",
    "\n",
    "    SG = subgraphs_backbone[sentiment]\n",
    "\n",
    "    # degree sizes (within backbone)\n",
    "    deg = dict(G_backbone_W1.degree())\n",
    "    node_sizes = [10 + 4 * deg[n] for n in SG.nodes()]\n",
    "\n",
    "    # edges and nodes\n",
    "    nx.draw_networkx_edges(\n",
    "        SG, pos_global, ax=ax,\n",
    "        width=0.5, alpha=0.5\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        SG, pos_global, ax=ax,\n",
    "        node_color=sentiment_colors[sentiment],\n",
    "        node_size=node_sizes,\n",
    "        alpha=1\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{sentiment.capitalize()} (backbone)\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987902e",
   "metadata": {},
   "source": [
    "## Detect emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5615906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# model returns logits for these labels:\n",
    "EMOTION_LABELS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65783c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(text):\n",
    "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "        return None, None\n",
    "\n",
    "    # tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # get model output\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # softmax for probabilities\n",
    "    probs = torch.softmax(logits, dim=1).numpy()[0]\n",
    "\n",
    "    # get top emotion\n",
    "    top_idx = np.argmax(probs)\n",
    "    top_emotion = EMOTION_LABELS[top_idx]\n",
    "\n",
    "    return top_emotion, dict(zip(EMOTION_LABELS, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077758db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first clean text of the dataframe\n",
    "print(df[\"clean_text\"].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7813b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nodes_by_sentiment = {}\n",
    "\n",
    "for category in [\"pro\", \"anti\", \"news\", \"neutral\"]:\n",
    "    # Filter nodes in this sentiment group\n",
    "    nodes_in_group = [\n",
    "        n for n in G.nodes()\n",
    "        if G.nodes[n].get(\"sentiment_label\") == category\n",
    "    ]\n",
    "\n",
    "    # Sort these nodes by degree\n",
    "    top_nodes = sorted(\n",
    "        nodes_in_group,\n",
    "        key=lambda n: deg.get(n, 0),\n",
    "        reverse=True\n",
    "    )[:1000]\n",
    "\n",
    "    top_nodes_by_sentiment[category] = top_nodes\n",
    "\n",
    "selected_nodes = (\n",
    "    top_nodes_by_sentiment[\"pro\"] +\n",
    "    top_nodes_by_sentiment[\"anti\"] +\n",
    "    top_nodes_by_sentiment[\"news\"] +\n",
    "    top_nodes_by_sentiment[\"neutral\"]\n",
    ")\n",
    "\n",
    "df_subset = df[df[\"tweetid\"].isin(selected_nodes)].copy()\n",
    "print(\"Selected tweets:\", len(df_subset))\n",
    "\n",
    "emotions = []\n",
    "emotion_probs = []\n",
    "\n",
    "for row in df_subset.itertuples(index=False):\n",
    "    emotion, prob_dict = get_emotion(row.clean_text)\n",
    "    emotions.append(emotion)\n",
    "    emotion_probs.append(prob_dict)\n",
    "\n",
    "df_subset[\"emotion\"] = emotions\n",
    "df_subset[\"emotion_probs\"] = emotion_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure tweetid matches node IDs (string)\n",
    "df_subset[\"tweetid\"] = df_subset[\"tweetid\"].astype(str)\n",
    "\n",
    "# Build mapping: tweetid -> emotion\n",
    "emotion_attr = df_subset.set_index(\"tweetid\")[\"emotion\"].to_dict()\n",
    "\n",
    "# Build mapping: tweetid -> emotion_probs (dict of 6 probs)\n",
    "emotion_probs_attr = df_subset.set_index(\"tweetid\")[\"emotion_probs\"].to_dict()\n",
    "\n",
    "# Attach as node attributes on G\n",
    "nx.set_node_attributes(G, emotion_attr, \"emotion\")\n",
    "nx.set_node_attributes(G, emotion_probs_attr, \"emotion_probs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15539fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1) Build four subnetworks based on sentiment_label ----\n",
    "sentiments = [\"pro\", \"anti\", \"news\", \"neutral\"]\n",
    "\n",
    "subgraphs = {\n",
    "    s: G.subgraph([\n",
    "        n for n in G.nodes()\n",
    "        if G.nodes[n].get(\"sentiment_label\") == s\n",
    "    ]).copy()\n",
    "    for s in sentiments\n",
    "}\n",
    "\n",
    "# ---- 2) Emotion colors ----\n",
    "emotion_colors = {\n",
    "    \"anger\":    \"indianred\",\n",
    "    \"disgust\":  \"orange\",\n",
    "    \"fear\":     \"slateblue\",\n",
    "    \"joy\":      \"forestgreen\",\n",
    "    \"sadness\":  \"cornflowerblue\",\n",
    "    \"surprise\": \"lime\",\n",
    "}\n",
    "\n",
    "# ---- 3) Plot the four networks next to each other ----\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 6))\n",
    "\n",
    "for ax, sentiment in zip(axes, sentiments):\n",
    "    SG_full = subgraphs[sentiment]\n",
    "\n",
    "    if SG_full.number_of_nodes() == 0:\n",
    "        ax.set_title(f\"{sentiment.capitalize()} Network (no nodes)\")\n",
    "        ax.set_axis_off()\n",
    "        continue\n",
    "\n",
    "    # Top 1000 nodes by degree (within this sentiment group)\n",
    "    deg_full = dict(SG_full.degree())\n",
    "    top_nodes = sorted(deg_full, key=deg_full.get, reverse=True)[:1000]\n",
    "    SG = SG_full.subgraph(top_nodes).copy()\n",
    "\n",
    "    # Layout\n",
    "    pos = nx.forceatlas2_layout(\n",
    "        SG,\n",
    "        seed=42,\n",
    "        max_iter=1000,\n",
    "        distributed_action=False,\n",
    "        strong_gravity=True\n",
    "    )\n",
    "\n",
    "    # Node sizes\n",
    "    deg = dict(SG.degree())\n",
    "    node_sizes = [3 + 2 * deg[n] for n in SG.nodes()]\n",
    "\n",
    "    # Node colors based on EMOTION\n",
    "    node_colors = [\n",
    "        emotion_colors.get(G.nodes[n].get(\"emotion\"), \"#999999\")\n",
    "        for n in SG.nodes()\n",
    "    ]\n",
    "\n",
    "    # Draw network\n",
    "    nx.draw_networkx_edges(SG, pos, ax=ax, width=0.3, alpha=0.3)\n",
    "    nx.draw_networkx_nodes(\n",
    "        SG,\n",
    "        pos,\n",
    "        ax=ax,\n",
    "        node_size=node_sizes,\n",
    "        node_color=node_colors,\n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{sentiment.capitalize()} Network (top 1000)\\nColored by Emotion\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# ---- 4) Add one shared legend on the right ----\n",
    "legend_handles = [\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        marker=\"o\",\n",
    "        linestyle=\"\",\n",
    "        markersize=8,\n",
    "        color=color,\n",
    "        label=emotion.capitalize()\n",
    "    )\n",
    "    for emotion, color in emotion_colors.items()\n",
    "]\n",
    "\n",
    "# Make room on the right for the legend\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "\n",
    "fig.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Emotion\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.92, 0.5)\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_ccdf(data):\n",
    "    data = np.array(data)\n",
    "    data = np.sort(data)\n",
    "    n = len(data)\n",
    "    # CCDF: P(X ≥ x)\n",
    "    ccdf = 1.0 - np.arange(1, n + 1) / n\n",
    "    return data, ccdf\n",
    "\n",
    "# Plot: top row = histograms, bottom row = CCDFs\n",
    "fig, axes = plt.subplots(2, 4, figsize=(22, 8))\n",
    "\n",
    "for col, sentiment in enumerate(sentiments):\n",
    "    SG = subgraphs[sentiment]\n",
    "\n",
    "    if SG.number_of_nodes() == 0:\n",
    "        axes[0, col].set_title(f\"{sentiment.capitalize()} Network (no nodes)\")\n",
    "        axes[0, col].set_axis_off()\n",
    "        axes[1, col].set_axis_off()\n",
    "        continue\n",
    "\n",
    "    degrees = [d for _, d in SG.degree()]\n",
    "\n",
    "    # --- Top row: histogram ---\n",
    "    ax_hist = axes[0, col]\n",
    "    ax_hist.hist(degrees, bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "    ax_hist.set_title(f\"{sentiment.capitalize()} Network Degree Distribution\")\n",
    "    ax_hist.set_xlabel(\"Degree\")\n",
    "    ax_hist.set_ylabel(\"Frequency\")\n",
    "\n",
    "    # --- Bottom row: CCDF ---\n",
    "    ax_ccdf = axes[1, col]\n",
    "    x, y = compute_ccdf(degrees)\n",
    "    ax_ccdf.plot(x, y, marker=\".\", linestyle=\"-\")\n",
    "    ax_ccdf.set_xlabel(\"Degree\")\n",
    "    ax_ccdf.set_ylabel(\"CCDF  (P(Degree ≥ x))\")\n",
    "    ax_ccdf.set_title(f\"{sentiment.capitalize()} Network Degree CCDF\")\n",
    "\n",
    "    # Optional: use log scale if you like (often helpful for degree)\n",
    "    ax_ccdf.set_xscale(\"log\")\n",
    "    ax_ccdf.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
